{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2XhX9iIaHusezQMBzN0oy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sqbitegh/Colabs/blob/main/DataAnalyst.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXyWAHu2aFAD"
      },
      "outputs": [],
      "source": [
        "!pip install toolz==0.12.0\n",
        "#!pip install matplotlib==3.7.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Callable, Tuple\n",
        "from toolz import pipe, map, filter, partial, reduce, concat, take, drop\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import plotly.express as px\n"
      ],
      "metadata": {
        "id": "RoXWcvbAca2N"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Callable, Tuple\n",
        "from toolz import pipe, map, filter, partial, reduce, concat, take, drop\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
        "\n",
        "import plotly.express as px\n",
        "\n",
        "def read_vectors(filepath: str, max_rows: int = None) -> List[List[float]]:\n",
        "  \"\"\"Reads a file containing newline-separated vectors and returns a list of vectors.\"\"\"\n",
        "  with open(filepath, 'r') as file:\n",
        "      if max_rows is None:\n",
        "        return [[float(num) for num in line.split()] for line in file if line.strip() and 'end' not in line]\n",
        "      else:\n",
        "        return [[float(num) for num in line.split()] for line in file if line.strip() and 'end' not in line][:max_rows]\n",
        "    #return [[float(num) for num in line.split()] for line in file if line.strip()]\n",
        "\n",
        "def map_vectors(func: Callable[[List[float]], List[float]], vectors: List[List[float]]) -> List[List[float]]:\n",
        "  \"\"\"Applies a function to each vector in the list.\"\"\"\n",
        "  return list(map(func, vectors))\n",
        "\n",
        "def filter_vectors(predicate: Callable[[List[float]], bool], vectors: List[List[float]]) -> List[List[float]]:\n",
        "  \"\"\"Filters the list of vectors based on a predicate.\"\"\"\n",
        "  return list(filter(predicate, vectors))\n",
        "\n",
        "def sort_vectors_by_column(vectors: List[List[float]], column_index: int, reverse: bool = False) -> List[List[float]]:\n",
        "  \"\"\"Sorts the list of vectors by a specific column.\"\"\"\n",
        "  return sorted(vectors, key=lambda vector: vector[column_index], reverse=reverse)\n",
        "\n",
        "def zip_vectors(vectors1: List[List[float]], vectors2: List[List[float]]) -> List[Tuple[List[float], List[float]]]:\n",
        "  \"\"\"Zips two lists of vectors together.\"\"\"\n",
        "  return list(zip(vectors1, vectors2))\n",
        "\n",
        "def concat_vectors(vectors1: List[List[float]], vectors2: List[List[float]]) -> List[List[float]]:\n",
        "  \"\"\"Concatenates two lists of vectors.\"\"\"\n",
        "  return list(concat([vectors1, vectors2]))\n",
        "\n",
        "def cut_vectors(vectors: List[List[float]], start_index: int, end_index: int) -> List[List[float]]:\n",
        "  \"\"\"Cuts a list of vectors by index ranges.\"\"\"\n",
        "  return list(take(end_index, drop(start_index, vectors)))\n",
        "\n",
        "def read_bool_vector(filepath: str) -> List[float]:\n",
        "  \"\"\"Reads a file containing newline-separated boolean strings (True/False)\n",
        "  and converts them to a list of floats (1.0/0.0).\"\"\"\n",
        "  with open(filepath, 'r') as file:\n",
        "    return [1.0 if line.strip() == 'True' else 0.0 for line in file if 'end' not in line]\n",
        "\n",
        "def add_dimension(vectors: List[List[float]], new_dimension: List[float]) -> List[List[float]]:\n",
        "    \"\"\"Adds a new dimension as the first element to each vector.\"\"\"\n",
        "    return [[new_val] + vec for new_val, vec in zip(new_dimension, vectors)]\n",
        "\n",
        "def squeeze_columns(vectors: List[List[float]], c1: int, c2: int) -> List[List[float]]:\n",
        "    \"\"\"Squeezes columns from c1 to c2 (inclusive) into a single column by addition.\n",
        "    Handles c1=0 correctly.\n",
        "    \"\"\"\n",
        "    return list(map(lambda vector: ([sum(vector[c1:c2])] + vector[c2:]) if c1 == 0\n",
        "                                  else (vector[:c1-1] + [sum(vector[c1-1:c2])] + vector[c2:]),\n",
        "                   vectors))\n",
        "\n",
        "def print_vector_info(vectors: List[List[float]]) -> None:\n",
        "  \"\"\"Prints the size and dimensions of the list of vectors.\"\"\"\n",
        "  num_vectors = len(vectors)\n",
        "  if num_vectors > 0:\n",
        "    vector_dim = len(vectors[0])\n",
        "  else:\n",
        "    vector_dim = 0  # Handle empty list case\n",
        "\n",
        "  print(f\"Number of vectors: {num_vectors}\")\n",
        "  print(f\"Dimension of vectors: {vector_dim}\")\n",
        "\n",
        "  # Using NumPy for a more concise output\n",
        "  if num_vectors > 0:\n",
        "    print(f\"Shape of vectors (NumPy): {np.array(vectors).shape}\")\n",
        "\n",
        "\n",
        "def visualize_output(output):\n",
        "    \"\"\"Visualizes the output matrix using matplotlib with a hybrid colormap.\"\"\"\n",
        "    # Define colors for discrete values 1, 2, 3\n",
        "    discrete_colors = {\n",
        "        1: 'blue',\n",
        "        2: 'yellow',\n",
        "        3: 'red'\n",
        "    }\n",
        "\n",
        "    # Define a continuous colormap for values between -10 and 10\n",
        "    continuous_cmap = plt.cm.RdYlGn_r # Red-Yellow-Green reversed to get Blue-Green-Red\n",
        "\n",
        "    # Create a custom colormap\n",
        "    # We'll map values 1, 2, 3 to distinct indices outside the continuous range\n",
        "    # For example, map 1 to -11, 2 to -12, 3 to -13\n",
        "    # The continuous range will be mapped from -10 to 10\n",
        "    all_colors = []\n",
        "    bounds = []\n",
        "\n",
        "    # Add colors for values outside the -10 to 10 range (for 1, 2, 3)\n",
        "    # Map 1 to -13, 2 to -12, 3 to -11 to keep them distinct and below -10\n",
        "    all_colors.append(discrete_colors[1])\n",
        "    bounds.append(-13)\n",
        "    all_colors.append(discrete_colors[2])\n",
        "    bounds.append(-12)\n",
        "    all_colors.append(discrete_colors[3])\n",
        "    bounds.append(-11)\n",
        "\n",
        "\n",
        "    # Add colors from the continuous colormap\n",
        "    num_continuous_colors = 256 # Number of colors in the continuous colormap\n",
        "    continuous_bounds = np.linspace(-10, 10, num_continuous_colors)\n",
        "    for i in range(num_continuous_colors):\n",
        "        all_colors.append(continuous_cmap(i/num_continuous_colors))\n",
        "        bounds.append(continuous_bounds[i])\n",
        "\n",
        "    # Ensure bounds are strictly increasing\n",
        "    bounds = sorted(list(set(bounds)))\n",
        "\n",
        "    # Create the custom colormap\n",
        "    cmap = ListedColormap(all_colors)\n",
        "    norm = plt.Normalize(min(bounds), max(bounds))\n",
        "\n",
        "\n",
        "    num_rows = len(output)\n",
        "    if num_rows == 0:\n",
        "        print(\"Output is empty. Cannot visualize.\")\n",
        "        return\n",
        "    num_cols = len(output[0]) if num_rows > 0 else 0\n",
        "    if num_cols == 0:\n",
        "        print(\"Output rows are empty. Cannot visualize.\")\n",
        "        return\n",
        "\n",
        "    # Convert output to a NumPy array\n",
        "    output_array = np.array(output)\n",
        "\n",
        "    # Map discrete values to their chosen indices\n",
        "    mapped_output = np.copy(output_array)\n",
        "    mapped_output[mapped_output == 1] = -13\n",
        "    mapped_output[mapped_output == 2] = -12\n",
        "    mapped_output[mapped_output == 3] = -11\n",
        "\n",
        "\n",
        "    # Determine figure size based on the number of rows and columns\n",
        "    fig_width = num_cols * 0.1\n",
        "    fig_height = num_rows * 0.1\n",
        "\n",
        "    plt.figure(figsize=(fig_width, fig_height))\n",
        "\n",
        "    # Display the output using imshow with the custom colormap and normalization\n",
        "    plt.imshow(mapped_output, aspect='auto', interpolation='nearest', cmap=cmap, norm=norm)\n",
        "    plt.colorbar() # Add a colorbar to show the mapping\n",
        "\n",
        "    # Set y-axis ticks to show every 10 rows\n",
        "    plt.yticks(np.arange(0, num_rows, 10))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def visualize_output2(output, columns, s_row=0, n_rows=None):\n",
        "  \"\"\"\n",
        "  Visualizes the output based on specified columns using Plotly.\n",
        "\n",
        "  Args:\n",
        "    output: The output data (list of lists).\n",
        "    columns: A list of column indices to visualize (length 2 for 2D, 3 for 3D).\n",
        "  \"\"\"\n",
        "  if len(columns) < 2 or len(columns) > 3:\n",
        "    print(\"Please provide either 2 or 3 column indices for visualization.\")\n",
        "    return\n",
        "\n",
        "  # Convert output to a NumPy array for easier column access\n",
        "  output_array = np.array(output)\n",
        "  if n_rows is not None:\n",
        "      output_array = output_array[s_row:n_rows]\n",
        "  else:\n",
        "      output_array = output_array[s_row:]\n",
        "\n",
        "  if len(columns) == 2:\n",
        "    x_col = columns[0]\n",
        "    y_col = columns[1]\n",
        "    if x_col >= output_array.shape[1] or y_col >= output_array.shape[1]:\n",
        "      print(\"Invalid column index provided.\")\n",
        "      return\n",
        "\n",
        "    fig = px.scatter(x=output_array[:, x_col], y=output_array[:, y_col],  width=300, height=300)\n",
        "    fig.update_layout(\n",
        "        xaxis_title=f\"Column {x_col}\",\n",
        "        yaxis_title=f\"Column {y_col}\",\n",
        "        title=\"2D Scatter Plot\"\n",
        "    )\n",
        "    fig.show()\n",
        "\n",
        "  elif len(columns) == 3:\n",
        "    x_col = columns[0]\n",
        "    y_col = columns[1]\n",
        "    z_col = columns[2]\n",
        "    if x_col >= output_array.shape[1] or y_col >= output_array.shape[1] or z_col >= output_array.shape[1]:\n",
        "      print(\"Invalid column index provided.\")\n",
        "      return\n",
        "\n",
        "    fig = px.scatter_3d(x=output_array[:, x_col], y=output_array[:, y_col], z=output_array[:, z_col], width=300, height=300)\n",
        "    fig.update_layout(\n",
        "        scene = dict(\n",
        "            xaxis_title=f\"Column {x_col}\",\n",
        "            yaxis_title=f\"Column {y_col}\",\n",
        "            zaxis_title=f\"Column {z_col}\"),\n",
        "        title=\"3D Scatter Plot\"\n",
        "    )\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "SHbXfzkPcdUY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_datavector(activations_filename, correctness_vals):\n",
        "  vectors = read_vectors(activations_filename, None)  # Assuming vectors are stored in 'vectors.txt'\n",
        "  if correctness_vals is None:\n",
        "    bool_vector = [1.0] * len(vectors)\n",
        "  else:\n",
        "    bool_vector = read_bool_vector(correctness_vals)  # Assuming boolean strings are in 'bool_vector.txt'\n",
        "  print_vector_info(vectors)\n",
        "  #print(f\"bool_vector {bool_vector}\")\n",
        "  # Add the boolean vector as the first dimension to the existing vectors\n",
        "  merged_vectors = add_dimension(vectors, bool_vector) #if not equal length truncate to shorter\n",
        "\n",
        "  # Add a sequence number as the last column\n",
        "  for i in range(len(merged_vectors)):\n",
        "    merged_vectors[i].append(float(i))\n",
        "\n",
        "  print(f\"merged_vectors {merged_vectors[:10]}\")\n",
        "  print_vector_info(merged_vectors)\n",
        "  return merged_vectors\n",
        "\n",
        "def process_vectors_EuclChart(merged_vectors,cols, s_row, n_rows):\n",
        "  visualize_output2(merged_vectors, cols, s_row, n_rows)\n",
        "\n",
        "\n",
        "def process_vectors(activations_filename, correctness_vals, sort_range, max_rows):\n",
        "  vectors = read_vectors(activations_filename, max_rows)  # Assuming vectors are stored in 'vectors.txt'\n",
        "  if correctness_vals is None:\n",
        "    bool_vector = [1.0] * len(vectors)\n",
        "  else:\n",
        "    bool_vector = read_bool_vector(correctness_vals)  # Assuming boolean strings are in 'bool_vector.txt'\n",
        "  print_vector_info(vectors)\n",
        "  print(f\"bool_vector {bool_vector}\")\n",
        "\n",
        "  # Add the boolean vector as the first dimension to the existing vectors\n",
        "  merged_vectors = add_dimension(vectors, bool_vector)\n",
        "  print(f\"merged_vectors {merged_vectors}\")\n",
        "  print_vector_info(merged_vectors)\n",
        "  #merged_vectors = squeeze_columns(merged_vectors, 1, 6)\n",
        "  #merged_vectors = squeeze_columns(merged_vectors, 8, 11)\n",
        "  print(f\"merged_vectors squeezed {merged_vectors}\")\n",
        "  print_vector_info(merged_vectors)\n",
        "  print(\"filterby first column\")\n",
        "  merged_vectors = filter_vectors(lambda vector: vector[0] == 1.0, merged_vectors)\n",
        "  print_vector_info(merged_vectors)\n",
        "  process_vectors2(merged_vectors, sort_range)\n",
        "\n",
        "def process_vectors4(activations_filename, correctness_vals, sort_range, max_rows, squeeze_factor):\n",
        "    datavector = initialize_datavector(activations_filename, correctness_vals)\n",
        "    print_vector_info(datavector)\n",
        "\n",
        "    #squeeze_factor = 32\n",
        "    squeezed_datavector = []\n",
        "    for vector in datavector:\n",
        "        new_vector = []\n",
        "        for i in range(1, len(vector)-1, squeeze_factor):\n",
        "            new_vector.append(sum(vector[i:i+squeeze_factor]) / squeeze_factor)\n",
        "        # Add the first column (correctness value) and the last column (sequence number) back to the new vector\n",
        "        squeezed_datavector.append([vector[0]] + new_vector + [vector[-1]/10.0])\n",
        "\n",
        "\n",
        "    print_vector_info(squeezed_datavector)\n",
        "    process_vectors2(squeezed_datavector, sort_range)\n",
        "\n",
        "def process_vectors2(merged_vectors, sort_range):\n",
        "  if sort_range is None:\n",
        "    sorted_vectors = merged_vectors\n",
        "    result = process_vectors3(sorted_vectors)\n",
        "    print(f\"output {result}\")\n",
        "    print_vector_info(result)\n",
        "    visualize_output(result)\n",
        "  else:\n",
        "    for sort_column in sort_range:\n",
        "      sorted_vectors = sort_vectors_by_column(merged_vectors, column_index=sort_column)\n",
        "      result = process_vectors3(sorted_vectors)\n",
        "      print(f\"output {result}\")\n",
        "      print_vector_info(result)\n",
        "      visualize_output(result)\n",
        "  #sorted_vectors = merged_vectors\n",
        "  #sorted_vectors = filter_vectors(lambda vector: vector[0] == 1.0, sorted_vectors)\n",
        "\n",
        "  #print (f\"sorted_vectors {sorted_vectors}\")\n",
        "  #print_vector_info(sorted_vectors)\n",
        "\n",
        "def process_vectors3(sorted_vectors):\n",
        "  compute_deriv_sign = False\n",
        "    # 2. Compare adjacent elements in each column and generate output\n",
        "  output = []\n",
        "  for i in range(len(sorted_vectors)):\n",
        "    current_vector_output = []  # Output for the current vector\n",
        "    # Skip the first row for comparison\n",
        "    if i > 0:\n",
        "      for j in range(1, len(sorted_vectors[i])-1):  # Start from the second column (index 1)\n",
        "        if compute_deriv_sign == True:\n",
        "          if sorted_vectors[i][j] > sorted_vectors[i - 1][j]:\n",
        "            current_vector_output.append(3)\n",
        "          elif sorted_vectors[i][j] == sorted_vectors[i - 1][j]:\n",
        "            current_vector_output.append(2)\n",
        "          else:\n",
        "            current_vector_output.append(1)\n",
        "        else:\n",
        "          current_vector_output.append( sorted_vectors[i][j] )\n",
        "      current_vector_output.append( sorted_vectors[i][len(sorted_vectors[i])-1] )\n",
        "      output.append(current_vector_output)  # Append output for current vector to overall output\n",
        "  return output"
      ],
      "metadata": {
        "id": "4BShQ7lWenvw"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "process_vectors('activations_fc_input_d64_h1_epoch_4_test.txt', 'corrects_list_d64_h1_epoch_4_test.txt', range(1,32))\n",
        "process_vectors('activations_fc_input_d64_h1_epoch_4_test.txt', 'corrects_list_d64_h1_epoch_4_test.txt', None)\n",
        "#process_vectors('activations_fc_input_d64_h1_epoch_4_train.txt', 'corrects_list_d64_h1_epoch_4_train.txt', None)\n",
        "\n"
      ],
      "metadata": {
        "id": "7w2jaMTQoBaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from tinystories\n",
        "process_vectors('sample_data/activations_rec4ep20_f10000.txt',None , None, 1000)\n",
        "process_vectors('sample_data/activations_rec4ep20_f10000.txt',None , range(5, 12), 600)\n"
      ],
      "metadata": {
        "id": "VbObOX9gN9Zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#from tinystories, 2-3D"
      ],
      "metadata": {
        "id": "k3atLflGv921"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datavector = initialize_datavector('sample_data/activations_rec6ep20_f10000.txt',None)\n",
        "#datavector = initialize_datavector('sample_data/activations_rec4ep20_f10000.txt',None)\n"
      ],
      "metadata": {
        "id": "_CIVf3pEvRFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_vectors_EuclChart(datavector, [17 ,18], 700,800)\n"
      ],
      "metadata": {
        "id": "d7FJM86d9xa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"before sort\")\n",
        "print([row[:5] for row in datavector[0:10]])\n",
        "sorted_vectors = sort_vectors_by_column(datavector[0:5000], column_index=10)\n",
        "print(\"\\n\\n\\nafter sort\")\n",
        "print([row[:5] for row in sorted_vectors[0:10]])\n",
        "#sorted_vectors = datavector\n",
        "for x_col in range(10, 11, 1):\n",
        "    for y_col in range(x_col-4, x_col+10, 1):\n",
        "      process_vectors_EuclChart(sorted_vectors, [x_col ,y_col], 1,80)\n",
        "\"\"\"\n",
        "for x_col in range(1, 20, 1):\n",
        "    for y_col in range(x_col+1, x_col+2, 1):\n",
        "      process_vectors_EuclChart(sorted_vectors, [x_col ,y_col], 10,100)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "DDcNni5nqxXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Phi2"
      ],
      "metadata": {
        "id": "YzkXbsJz-OPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "process_vectors('sample_data/activations_phi2_factor_c.txt',None , range(1, 12), 1000)\n"
      ],
      "metadata": {
        "id": "8TwcTL4s-QWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datavector = initialize_datavector('sample_data/activations_phi2_factor_c.txt',None)\n"
      ],
      "metadata": {
        "id": "V6wkHM4c_lZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_vectors4('sample_data/activations_phi2_factor_c3.txt',None , range(0, 30), 1000, squeeze_factor = 17)\n",
        "#/content/sample_data/activations_phi2_fcall_c2.txt"
      ],
      "metadata": {
        "id": "pgpDSKY2Xu6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_vectors_EuclChart(datavector, [8 ,9], 0,800)"
      ],
      "metadata": {
        "id": "VkoUynkU_oUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "tinyllama"
      ],
      "metadata": {
        "id": "DQRobcPcXhvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#/content/sample_data/activs_tinyllama_cprrec_cucumb.txt\n",
        "process_vectors4('sample_data/activs_tinyllama_cnorec_fact.txt',None , range(0, 8), 200, squeeze_factor = 63)\n",
        "\n",
        "\n",
        "#process_vectors4('sample_data/activations_tinyllama_factor_c5.txt',None , range(20, 33), 200, squeeze_factor = 63)\n",
        "#content/sample_data/activations_tinyllama_factor_c4.txt"
      ],
      "metadata": {
        "id": "3K1qhxNQXjrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tests"
      ],
      "metadata": {
        "id": "9i78SLFGZR_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test\n",
        "process_vectors('example_vectors.txt', 'example_bool_vector.txt', None)\n",
        "process_vectors('example_vectors.txt', 'example_bool_vector.txt', range(1,3))\n"
      ],
      "metadata": {
        "id": "ZmaF-DQSwlFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Usage\n",
        "vectors = read_vectors('example_vectors.txt')  # Assuming vectors are stored in 'vectors.txt'\n",
        "\n",
        "# Map: Double each element in each vector\n",
        "doubled_vectors = map_vectors(lambda vector: [x * 2 for x in vector], vectors)\n",
        "\n",
        "# Filter: Keep vectors where the first element is positive\n",
        "positive_vectors = filter_vectors(lambda vector: vector[0] > 0, vectors)\n",
        "\n",
        "# Sort: Sort vectors by the second column in descending order\n",
        "sorted_vectors = sort_vectors_by_column(vectors, column_index=1, reverse=True)\n",
        "\n",
        "# Zip: Combine two lists of vectors\n",
        "zipped_vectors = zip_vectors(vectors, doubled_vectors)\n",
        "\n",
        "# Concat: Concatenate two lists of vectors\n",
        "concatenated_vectors = concat_vectors(vectors, doubled_vectors)\n",
        "\n",
        "# Cut: Get vectors from index 2 to 5\n",
        "cut_vectors_result = cut_vectors(vectors, start_index=2, end_index=5)\n",
        "\n"
      ],
      "metadata": {
        "id": "k0ILIH3IcSKx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}