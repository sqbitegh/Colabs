{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sqbitegh/Colabs/blob/main/TinyStories_copy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "#preparations:\n",
        "#in /dataset put train.pt, validation.pt\n",
        "#/my_dataset/train and /my_dataset/validation put parquet\n",
        "#/my_tokenizer/ put special_tokens_map.json, tokenizer.json, tokenizer_config.json\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZQRqZ23jjwsE",
        "outputId": "c3f77e4a-5fa1-4b4e-aa39-ffcf195d2543",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.5.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.5.1-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.4/491.4 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.1 dill-0.3.8 fsspec-2025.3.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#clear GPU\n",
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "tEEOI8ezPn6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"HF_TOKEN\"] = \"hgf token\""
      ],
      "metadata": {
        "id": "eu2LRNzrm98Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import random\n",
        "import time\n",
        "import inspect\n",
        "from dataclasses import dataclass, fields\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import datasets\n",
        "import tokenizers\n",
        "import transformers  # for AutoTokenizer, using our own transformer implementation.\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "#saving activations\n",
        "import numpy as np\n",
        "\n",
        "epoch = 0\n",
        "def save_inputs_to_file(module, input, output):\n",
        "    global epoch\n",
        "    if(epoch % 5 != 0):\n",
        "      return\n",
        "    os.makedirs('lm_head_inputs', exist_ok=True)\n",
        "    input_tensor = input[0].cpu().detach().numpy()  # Move to CPU and detach\n",
        "\n",
        "    file_path = os.path.join('lm_head_inputs', f'input_epoch_{epoch}.txt')\n",
        "\n",
        "    with open(file_path, 'a') as f:  # Open in append mode\n",
        "        for data in input_tensor:\n",
        "            np.savetxt(f, data, fmt='%f')  # Use numpy.savetxt\n",
        "            f.write('\\n')\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class GPTConfig:\n",
        "    block_size: int = 128 # max sequence length\n",
        "    n_layer: int = 4 #12 # number of layers\n",
        "    n_head: int = 1 #12 # number of heads\n",
        "    n_embd: int = 128 #384 # embedding dimension\n",
        "    feed_forward_factor: float = 1.0 #1.8  # how much bigger the MLP blocks are than the model n_embd.  Conventionally 4.\n",
        "    vocab_size: int = 8192\n",
        "\n",
        "    data_dir: str = 'dataset'\n",
        "    expt_name: str = '384_dims_is_all_u_need'\n",
        "\n",
        "    batch_size: int = 256 #128\n",
        "    max_lr: float = 2e-3\n",
        "    min_lr: float = 2e-4\n",
        "    beta_1: float = 0.9\n",
        "    beta_2: float = 0.99\n",
        "    warmup_steps:int = 50\n",
        "    max_steps: int = 12000\n",
        "    max_runtime_seconds: int = 720\n",
        "\n",
        "    weight_decay: float = 0.12\n",
        "\n",
        "    need_epoch_reshuffle: bool = True\n",
        "    matmul_precision: str = 'high' # medium, high, highest.\n",
        "    # Do various hacky things (don't use torch.compile, don't load training data) to speed up the run.\n",
        "    # # We are checking for runnability rather than model quality.\n",
        "    smoke_test: bool = False\n",
        "\n",
        "    def __str__(self):\n",
        "        return '\\n'.join([f'{field.name}: {str(getattr(self, field.name))}' for field in fields(self)])\n",
        "\n",
        "\n",
        "class Logger():\n",
        "    def __init__(self, expt_name, smoke_test):\n",
        "        self.log_dir = f'logs/{expt_name}{\"_smoke\" if smoke_test else \"\"}'\n",
        "        os.makedirs(self.log_dir, exist_ok=True)\n",
        "        self.log_file = f'{self.log_dir}/log.txt'\n",
        "        with open(self.log_file, \"w\") as f:\n",
        "            f.write(\"\")\n",
        "\n",
        "    def log(self, msg):\n",
        "        print(msg)\n",
        "        with open(self.log_file, \"a\") as f:\n",
        "            f.write(f\"{msg}\\n\")\n",
        "\n",
        "config = GPTConfig()\n",
        "logger = Logger(os.path.join(config.expt_name), config.smoke_test) # open for writing to clear the file\n",
        "logger.log(str(config))\n",
        "\n",
        "\n",
        "class CausalSelfAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.n_embd % config.n_head == 0\n",
        "        # key, query, value projections for all heads, but in a batch\n",
        "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd)\n",
        "        # output projection\n",
        "        self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n",
        "        self.c_proj.NANOGPT_SCALE_INIT = 1\n",
        "        self.n_head = config.n_head\n",
        "        self.n_embd = config.n_embd\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
        "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
        "        # nh is \"number of heads\", hs is \"head size\", and C (number of channels) = nh * hs\n",
        "        # e.g. in GPT-2 (124M), n_head=12, hs=64, so nh*hs=C=768 channels in the Transformer\n",
        "        qkv = self.c_attn(x)\n",
        "        q, k, v = qkv.split(self.n_embd, dim=2)\n",
        "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "        y = F.scaled_dot_product_attention(q, k, v, is_causal=True) # flash attention\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
        "        # output projection\n",
        "        y = self.c_proj(y)\n",
        "        return y\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        ff_exp = int(config.feed_forward_factor * config.n_embd)\n",
        "        ff_exp -= ff_exp % 64\n",
        "        assert ff_exp % 64 == 0\n",
        "        self.c_fc    = nn.Linear(config.n_embd, ff_exp)\n",
        "        self.gelu    = nn.GELU(approximate='tanh')\n",
        "        self.c_proj  = nn.Linear(ff_exp, config.n_embd)\n",
        "        self.c_proj.NANOGPT_SCALE_INIT = 1\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.c_fc(x)\n",
        "        x = self.gelu(x)\n",
        "        x = self.c_proj(x)\n",
        "        return x\n",
        "\n",
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.ln_1 = nn.LayerNorm(config.n_embd)\n",
        "        self.attn = CausalSelfAttention(config)\n",
        "        self.ln_2 = nn.LayerNorm(config.n_embd)\n",
        "        self.mlp = MLP(config)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.ln_1(x))\n",
        "        x = x + self.mlp(self.ln_2(x))\n",
        "        return x\n",
        "\n",
        "class GPT(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.transformer = nn.ModuleDict(dict(\n",
        "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
        "            wpe = nn.Embedding(config.block_size, config.n_embd),\n",
        "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
        "            ln_f = nn.LayerNorm(config.n_embd),\n",
        "        ))\n",
        "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
        "\n",
        "        # weight sharing scheme\n",
        "        self.transformer.wte.weight = self.lm_head.weight\n",
        "\n",
        "        # init params\n",
        "        self.apply(self._init_weights)\n",
        "        self.activation_hook = self.lm_head.register_forward_hook(save_inputs_to_file)\n",
        "\n",
        "    def deregister_activation_hook(self):\n",
        "        \"\"\"Deregisters the activation hook if it is registered.\"\"\"\n",
        "        if self.activation_hook is not None:\n",
        "            self.activation_hook.remove()\n",
        "            self.activation_hook = None\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            std = 0.02\n",
        "            if hasattr(module, 'NANOGPT_SCALE_INIT'):\n",
        "                std *= (2 * self.config.n_layer) ** -0.5\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=std)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        # idx is of shape (B, T)\n",
        "        B, T = idx.size()\n",
        "        assert T <= self.config.block_size, f\"Cannot forward sequence of length {T}, block size is only {self.config.block_size}\"\n",
        "        # forward the token and posisition embeddings\n",
        "        pos = torch.arange(0, T, dtype=torch.long, device=idx.device) # shape (T)\n",
        "        pos_emb = self.transformer.wpe(pos) # position embeddings of shape (T, n_embd)\n",
        "        tok_emb = self.transformer.wte(idx) # token embeddings of shape (B, T, n_embd)\n",
        "        x = tok_emb + pos_emb\n",
        "        # forward the blocks of the transformer\n",
        "        for block in self.transformer.h:\n",
        "            x = block(x)\n",
        "        # forward the final layernorm and the classifier\n",
        "        x = self.transformer.ln_f(x)\n",
        "        logits = self.lm_head(x) # (B, T, vocab_size)\n",
        "        loss = None\n",
        "        if targets is not None:\n",
        "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
        "        return logits, loss\n",
        "\n",
        "    def configure_optimizers(self, weight_decay, learning_rate, device_type, beta1, beta2):\n",
        "        # start with all of the candidate parameters (that require grad)\n",
        "        param_dict = {pn: p for pn, p in self.named_parameters()}\n",
        "        param_dict = {pn: p for pn, p in param_dict.items() if p.requires_grad}\n",
        "        # create optim groups. Any parameters that is 2D will be weight decayed, otherwise no.\n",
        "        # i.e. all weight tensors in matmuls + embeddings decay, all biases and layernorms don't.\n",
        "        decay_params = [p for n, p in param_dict.items() if p.dim() >= 2]\n",
        "        nodecay_params = [p for n, p in param_dict.items() if p.dim() < 2]\n",
        "        optim_groups = [\n",
        "            {'params': decay_params, 'weight_decay': weight_decay},\n",
        "            {'params': nodecay_params, 'weight_decay': 0.0}\n",
        "        ]\n",
        "        num_decay_params = sum(p.numel() for p in decay_params)\n",
        "        num_nodecay_params = sum(p.numel() for p in nodecay_params)\n",
        "\n",
        "        logger.log(f\"num decayed parameter tensors: {len(decay_params)}, with {num_decay_params:,} parameters\")\n",
        "        logger.log(f\"num non-decayed parameter tensors: {len(nodecay_params)}, with {num_nodecay_params:,} parameters\")\n",
        "        # Create AdamW optimizer and use the fused version if it is available\n",
        "        fused_available = 'fused' in inspect.signature(torch.optim.AdamW).parameters\n",
        "        use_fused = fused_available and device_type == \"cuda\"\n",
        "        logger.log(f\"using fused AdamW: {use_fused}\")\n",
        "        optimizer = torch.optim.AdamW(optim_groups, lr=learning_rate, betas=(beta1, beta2), eps=1e-8, fused=use_fused)\n",
        "        return optimizer\n",
        "\n",
        "\n",
        "def load_tokens(filename):\n",
        "    return torch.load(filename).to(dtype=torch.long)\n",
        "\n",
        "\n",
        "class DataLoaderLite:\n",
        "    def __init__(self, data_dir, B, T, split, shuffle):\n",
        "        self.B, self.T, self.shuffle = B, T, shuffle\n",
        "        assert split in {'train', 'val'}\n",
        "\n",
        "        shards = os.listdir(data_dir)\n",
        "        shards = [s for s in shards if split in s]\n",
        "        shards = sorted(shards)\n",
        "        shards = [os.path.join(data_dir, s) for s in shards]\n",
        "        self.shards = shards\n",
        "        assert len(shards) > 0, f\"no shards found for split {split}\"\n",
        "\n",
        "        logger.log(f\"found {len(shards)} shards for split {split}\")\n",
        "\n",
        "        self.current_shard, self.current_position = -1, 0\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        global epoch\n",
        "        epoch += 1\n",
        "        print(f'reset, epoch change {epoch}')\n",
        "        self.current_shard, self.current_position = (self.current_shard + 1) % len(self.shards), 0\n",
        "        self.tokens = load_tokens(self.shards[self.current_shard])\n",
        "        if self.shuffle:\n",
        "            start = time.time()\n",
        "            self.shuffle_tokens()\n",
        "            logger.log(f\"shuffled {self.tokens.shape[0]} tokens in {time.time() - start:.1f}s\")\n",
        "\n",
        "    def shuffle_tokens(self, DOCUMENT_END: int = 0):\n",
        "        \"\"\"Shuffle documents in a flat token tensor while keeping each document contiguous.\"\"\"\n",
        "        end_indices = (self.tokens == DOCUMENT_END).nonzero(as_tuple=False).flatten().tolist()\n",
        "\n",
        "        # If the last token is not DOCUMENT_END, consider it as an incomplete document\n",
        "        if not end_indices or end_indices[-1] != len(self.tokens) - 1:\n",
        "            end_indices.append(len(self.tokens) - 1)\n",
        "\n",
        "        documents = []\n",
        "        prev_end = -1  # Start before the first token\n",
        "\n",
        "        for end in end_indices:\n",
        "            # Slice from the token after the previous DOCUMENT_END to the current DOCUMENT_END\n",
        "            # +1 to include the DOCUMENT_END token in the document\n",
        "            doc = self.tokens[prev_end + 1 : end + 1]\n",
        "            documents.append(doc)\n",
        "            prev_end = end\n",
        "\n",
        "        random.shuffle(documents)\n",
        "        self.tokens = torch.cat(documents, dim=0)\n",
        "\n",
        "    def next_batch(self):\n",
        "        B, T = self.B, self.T\n",
        "        buf = self.tokens[self.current_position : self.current_position+B*T+1]\n",
        "        x = (buf[:-1]).view(B, T) # inputs\n",
        "        y = (buf[1:]).view(B, T) # targets\n",
        "        # advance the position in the tensor\n",
        "        self.current_position += B * T\n",
        "        # if loading the next batch would be out of bounds, advance to next shard\n",
        "        if self.current_position + (B * T + 1) > len(self.tokens):\n",
        "            self.reset()\n",
        "        return x, y\n",
        "\n",
        "\n",
        "def generate(model, enc, prompt, max_length, num_return_sequences):\n",
        "    model.eval()\n",
        "\n",
        "    eos_id = enc.get_vocab()['[EOS]']\n",
        "    tokens = enc.encode(prompt)\n",
        "    tokens = torch.tensor(tokens, dtype=torch.long)\n",
        "    tokens = tokens.unsqueeze(0).repeat(num_return_sequences, 1)\n",
        "    xgen = tokens.to('cuda')\n",
        "    sample_rng = torch.Generator(device='cuda')\n",
        "    sample_rng.manual_seed(42)\n",
        "    while xgen.size(1) < max_length:\n",
        "        # forward the model to get the logits\n",
        "        with torch.no_grad():\n",
        "            with torch.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
        "                logits, loss = model(xgen) # (B, T, vocab_size)\n",
        "            # take the logits at the last position\n",
        "            logits = logits[:, -1, :] # (B, vocab_size)\n",
        "            # get the probabilities\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            # do top-k sampling of 50 (huggingface pipeline default)\n",
        "            # topk_probs here becomes (B, 50), topk_indices is (B, 50)\n",
        "            topk_probs, topk_indices = torch.topk(probs, 50, dim=-1)\n",
        "            # select a token from the top-k probabilities\n",
        "            # note: multinomial does not demand the input to sum to 1\n",
        "            ix = torch.multinomial(topk_probs, 1, generator=sample_rng) # (B, 1)\n",
        "            # gather the corresponding indices\n",
        "            xcol = torch.gather(topk_indices, -1, ix) # (B, 1)\n",
        "            # append to the sequence\n",
        "            xgen = torch.cat((xgen, xcol), dim=1)\n",
        "    # logger.log the generated text\n",
        "    for i in range(num_return_sequences):\n",
        "        # look for EOS here to truncate.\n",
        "        first_eos = (xgen[i] == eos_id).nonzero()\n",
        "        if first_eos.size(0) > 0:\n",
        "            this_end = first_eos[0].item()\n",
        "        else:\n",
        "            this_end = max_length\n",
        "        tokens = xgen[i, :this_end].tolist()\n",
        "        decoded = enc.decode(tokens)\n",
        "        logger.log(f\"sample {i}: {decoded}\")\n",
        "\n",
        "    model.train()\n",
        "\n",
        "\n",
        "def preprocess_tokens_from_huggingface(dataset_dir):\n",
        "    def flatten_tensorize_dataset_split(it):\n",
        "        num_docs = len(it)\n",
        "        flattened_tokens = []\n",
        "        for doc in tqdm(it, desc='flattening', total=num_docs):\n",
        "            flattened_tokens.extend(doc)\n",
        "        return torch.tensor(flattened_tokens, dtype=torch.int16)\n",
        "\n",
        "    for split in ['validation', 'train']:\n",
        "        os.makedirs(dataset_dir, exist_ok=True)\n",
        "        fn = f'{dataset_dir}/{split}.pt'\n",
        "        if not os.path.exists(fn):\n",
        "            #logger.log('downloading and processing', split) #real\n",
        "            logger.log('downloading and processing')\n",
        "\n",
        "            #ds = datasets.load_dataset('activated-ai/tiny-stories-8k-tokens', split=split)\n",
        "            #ds = datasets.load_dataset('/my_dataset/', split=split)\n",
        "\n",
        "            features = datasets.Features({\n",
        "        'tokens': datasets.Sequence(datasets.Value(dtype='int32'))  # Changed dtype to int32 if needed\n",
        "    })\n",
        "            ds = datasets.load_dataset('parquet', data_files={'train': 'my_dataset/train/*.parquet', 'validation': 'my_dataset/validation/*.parquet'}, features=features)[split]\n",
        "\n",
        "\n",
        "            val_tensor = flatten_tensorize_dataset_split(ds['tokens'])\n",
        "            torch.save(val_tensor, fn)\n",
        "        else:\n",
        "            logger.log(f'skipping token preprocessing for {split} : using cache {fn}')\n",
        "\n",
        "class ExponentiallyWeightedMean:\n",
        "    def __init__(self, alpha=0.1, skip_first=False):\n",
        "        self.alpha = alpha  # Decay rate\n",
        "        self.mean = None  # The weighted mean\n",
        "        self.skip_first = skip_first  # Whether to skip the first value\n",
        "        self.first_value_skipped = False  # Flag to track if the first value was skipped\n",
        "\n",
        "    def update(self, new_value):\n",
        "        # If we are skipping the first value, ensure we track and skip it\n",
        "        if self.skip_first and not self.first_value_skipped:\n",
        "            self.first_value_skipped = True\n",
        "            return None  # Skip the first value\n",
        "\n",
        "        if self.mean is None:\n",
        "            # If mean is not set, initialize it with the first value\n",
        "            self.mean = new_value\n",
        "        else:\n",
        "            # Update the mean using exponential decay\n",
        "            self.mean = self.alpha * new_value + (1 - self.alpha) * self.mean\n",
        "\n",
        "        return self.mean\n",
        "\n",
        "def load_model_from_checkpoint(checkpoint_path):\n",
        "    def remove_orig_mod_prefix(state_dict):\n",
        "        return {k.replace('_orig_mod.', ''): v for k, v in state_dict.items()}\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    model = GPT(checkpoint['config'])\n",
        "    model.load_state_dict(remove_orig_mod_prefix(checkpoint['model']))\n",
        "    model.to('cuda')\n",
        "    return model\n",
        "\n",
        "\n",
        "def main():\n",
        "    assert torch.cuda.is_available()\n",
        "    device = \"cuda\"\n",
        "    device_type = \"cuda\"\n",
        "\n",
        "    torch.manual_seed(1337)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(1337)\n",
        "\n",
        "    enc = transformers.AutoTokenizer.from_pretrained('my_tokenizer/')\n",
        "\n",
        "    preprocess_tokens_from_huggingface(config.data_dir)\n",
        "\n",
        "    val_loader = DataLoaderLite(data_dir=config.data_dir, B=config.batch_size, T=config.block_size, split=\"val\", shuffle=False)\n",
        "    bytes_in_val_text = 19190318  # compute this on data load by using tokenizer on say, first 100k tokens in validation data.\n",
        "    bytes_per_token = bytes_in_val_text / val_loader.tokens.shape[0]\n",
        "    if not config.smoke_test:\n",
        "        train_loader = DataLoaderLite(data_dir=config.data_dir , B=config.batch_size, T=config.block_size, split=\"train\", shuffle=config.need_epoch_reshuffle)\n",
        "    else:\n",
        "        train_loader = val_loader\n",
        "\n",
        "    model = GPT(config)\n",
        "\n",
        "    torch.set_float32_matmul_precision(config.matmul_precision)\n",
        "\n",
        "    model.to(device)\n",
        "    use_compile = not config.smoke_test\n",
        "    if use_compile:\n",
        "        logger.log('using torch.compile')\n",
        "        model = torch.compile(model)\n",
        "\n",
        "\n",
        "    def get_lr(it, estimated_steps_in_time_limit=None):\n",
        "        lowest_maximum_steps = min(config.max_steps, estimated_steps_in_time_limit) if estimated_steps_in_time_limit is not None else config.max_steps\n",
        "\n",
        "        # 1) linear warmup for warmup_steps steps\n",
        "        if it < config.warmup_steps:\n",
        "            return config.max_lr * (it + 1) / config.warmup_steps\n",
        "        # 2) if it >= lowest_maximum_steps, return min learning rate\n",
        "        if it >= lowest_maximum_steps:\n",
        "            return config.min_lr\n",
        "        # 3) in between, use cosine decay down to min learning rate\n",
        "        decay_ratio = (it - config.warmup_steps) / (lowest_maximum_steps - config.warmup_steps)\n",
        "        assert 0 <= decay_ratio <= 1\n",
        "        decay_ratio = min(max(decay_ratio, 0), 1)  # Ensure decay_ratio is within [0, 1]\n",
        "        coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio))  # coeff starts at 1 and goes to 0\n",
        "        return config.min_lr + coeff * (config.max_lr - config.min_lr)\n",
        "\n",
        "\n",
        "    optimizer = model.configure_optimizers(weight_decay=config.weight_decay, learning_rate=config.max_lr,\n",
        "                                           device_type=device_type, beta1=config.beta_1, beta2=config.beta_2)\n",
        "\n",
        "    # create the log directory we will write checkpoints to and log to\n",
        "    log_dir = f'logs/{config.expt_name}'\n",
        "    if config.smoke_test:\n",
        "        log_dir += '_smoke'\n",
        "    os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "    t_start = time.time()\n",
        "    eval_checkpoint_exit = False\n",
        "    loss_accum = []\n",
        "\n",
        "    # Example usage:\n",
        "    mean_dt_ewma = ExponentiallyWeightedMean(alpha=0.01, skip_first=True)\n",
        "    estimated_steps_in_time_limit = None\n",
        "\n",
        "\n",
        "    for step in range(config.max_steps):\n",
        "        t0 = time.time()\n",
        "        eval_checkpoint_exit = (step == config.max_steps - 1) or eval_checkpoint_exit\n",
        "\n",
        "        # once in a while evaluate our validation loss\n",
        "        if (step % 250 == 0 and step > 0) or eval_checkpoint_exit:\n",
        "            if config.smoke_test:\n",
        "                logger.log('exiting due to smoke test')\n",
        "                eval_checkpoint_exit = True\n",
        "            model.eval()\n",
        "            generate(model, enc, \"Lily went to the park and\", 64, 4)\n",
        "\n",
        "            val_loader.reset()\n",
        "            with torch.no_grad():\n",
        "                val_loss_accum = 0.0\n",
        "                val_loss_steps = 20\n",
        "                for _ in range(val_loss_steps):\n",
        "\n",
        "                    x, y = val_loader.next_batch()\n",
        "                    x, y = x.to(device), y.to(device)\n",
        "                    with torch.autocast(device_type=device_type, dtype=torch.bfloat16):\n",
        "                        logits, loss = model(x, y)\n",
        "                    loss = loss / val_loss_steps\n",
        "                    val_loss_accum += loss.detach()\n",
        "\n",
        "            val_loss = val_loss_accum.item()\n",
        "            per_byte_loss = val_loss / bytes_per_token\n",
        "\n",
        "            logger.log(f'step {step} | val loss {val_loss:.4f} | byte loss {per_byte_loss:.4f} | ds {time.time() - t_start:.1f}s')\n",
        "\n",
        "            if step > 0 and (step % 5000 == 0 or eval_checkpoint_exit):\n",
        "                # optionally write model checkpoints\n",
        "                checkpoint_path = os.path.join(log_dir, f\"model_{step:05d}.pt\")\n",
        "                checkpoint = {\n",
        "                    'model': model.state_dict(),\n",
        "                    'config': model.config,\n",
        "                    'step': step,\n",
        "                    'val_loss': val_loss_accum.item()\n",
        "                }\n",
        "                # Store rng seeds too?\n",
        "\n",
        "                # if last step, save the optimzer state dict\n",
        "                if eval_checkpoint_exit:\n",
        "                    checkpoint['optimizer'] = optimizer.state_dict()\n",
        "                torch.save(checkpoint, checkpoint_path)\n",
        "\n",
        "            if eval_checkpoint_exit:\n",
        "                break\n",
        "\n",
        "\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        x, y = train_loader.next_batch()\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        with torch.autocast(device_type=device_type, dtype=torch.bfloat16):\n",
        "            logits, loss = model(x, y)\n",
        "        loss_accum.append(loss.detach())\n",
        "        loss.backward()\n",
        "        norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        # determine and set the learning rate for this iteration\n",
        "        lr = get_lr(step, estimated_steps_in_time_limit=estimated_steps_in_time_limit)\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "        optimizer.step()\n",
        "\n",
        "        if step % 10 == 0:\n",
        "            t1 = time.time()\n",
        "            dt = t1 - t0\n",
        "            ds = t1 - t_start\n",
        "            tokens_processed = train_loader.B * train_loader.T\n",
        "            tokens_per_sec = tokens_processed / dt\n",
        "            avg_loss = sum(loss_accum) / len(loss_accum)\n",
        "            loss_accum.clear()\n",
        "            if ds > config.max_runtime_seconds:\n",
        "                logger.log('exiting due to time limit')\n",
        "                eval_checkpoint_exit = True\n",
        "\n",
        "            mean_dt_ewma.update(dt)\n",
        "            if mean_dt_ewma.mean is not None:\n",
        "                remaining_steps = config.max_steps - step\n",
        "                remaining_time = config.max_runtime_seconds - ds\n",
        "                # let some time for the last step to finish\n",
        "                if (remaining_time < 0) and (remaining_time > -10):\n",
        "                    remaining_time = 0\n",
        "                assert remaining_time >= 0\n",
        "                remaining_steps_in_time_limit = int(remaining_time / mean_dt_ewma.mean)\n",
        "                estimated_steps_in_time_limit = step + remaining_steps_in_time_limit\n",
        "\n",
        "\n",
        "            per_byte_loss = avg_loss / bytes_per_token\n",
        "            logger.log(f'step {step:5d} | loss {avg_loss:.6f} | byte loss {per_byte_loss:.4f} | lr {lr:.4e} | norm {norm:.4f} | dt {dt*1000:.2f}ms | tok/sec: {tokens_per_sec:.2f} | ds {ds:.1f}s')\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "kw2VWlxijtyx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c48d4bb-4916-4fc5-bb78-091388d8ac5d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "block_size: 128\n",
            "n_layer: 2\n",
            "n_head: 1\n",
            "n_embd: 64\n",
            "feed_forward_factor: 1.0\n",
            "vocab_size: 8192\n",
            "data_dir: dataset\n",
            "expt_name: 384_dims_is_all_u_need\n",
            "batch_size: 256\n",
            "max_lr: 0.002\n",
            "min_lr: 0.0002\n",
            "beta_1: 0.9\n",
            "beta_2: 0.99\n",
            "warmup_steps: 50\n",
            "max_steps: 12000\n",
            "max_runtime_seconds: 720\n",
            "weight_decay: 0.12\n",
            "need_epoch_reshuffle: True\n",
            "matmul_precision: high\n",
            "smoke_test: False\n",
            "skipping token preprocessing for validation : using cache dataset/validation.pt\n",
            "skipping token preprocessing for train : using cache dataset/train.pt\n",
            "found 1 shards for split val\n",
            "reset, epoch change 1\n",
            "found 1 shards for split train\n",
            "reset, epoch change 2\n",
            "shuffled 117256624 tokens in 4.3s\n",
            "using torch.compile\n",
            "num decayed parameter tensors: 10, with 581,632 parameters\n",
            "num non-decayed parameter tensors: 18, with 1,408 parameters\n",
            "using fused AdamW: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:1948: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:1948: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:1948: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:1948: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step     0 | loss 9.004492 | byte loss 2.2012 | lr 4.0000e-05 | norm 1.3673 | dt 5905.43ms | tok/sec: 5548.79 | ds 5.9s\n",
            "step    10 | loss 8.920403 | byte loss 2.1806 | lr 4.4000e-04 | norm 1.0158 | dt 117.85ms | tok/sec: 278038.65 | ds 7.1s\n",
            "step    20 | loss 8.480705 | byte loss 2.0732 | lr 8.4000e-04 | norm 0.9547 | dt 109.69ms | tok/sec: 298736.17 | ds 8.3s\n",
            "step    30 | loss 7.722019 | byte loss 1.8877 | lr 1.2400e-03 | norm 0.9836 | dt 114.49ms | tok/sec: 286213.09 | ds 9.4s\n",
            "step    40 | loss 6.847356 | byte loss 1.6739 | lr 1.6400e-03 | norm 0.8835 | dt 112.37ms | tok/sec: 291615.47 | ds 10.5s\n",
            "step    50 | loss 6.218939 | byte loss 1.5203 | lr 2.0000e-03 | norm 0.5803 | dt 111.55ms | tok/sec: 293753.32 | ds 11.7s\n",
            "step    60 | loss 5.952970 | byte loss 1.4552 | lr 2.0000e-03 | norm 0.5074 | dt 115.91ms | tok/sec: 282713.02 | ds 12.8s\n",
            "step    70 | loss 5.836118 | byte loss 1.4267 | lr 2.0000e-03 | norm 0.2881 | dt 115.57ms | tok/sec: 283524.26 | ds 14.0s\n",
            "step    80 | loss 5.689956 | byte loss 1.3909 | lr 1.9999e-03 | norm 0.7066 | dt 117.03ms | tok/sec: 279996.81 | ds 15.1s\n",
            "step    90 | loss 5.564453 | byte loss 1.3603 | lr 1.9998e-03 | norm 0.4996 | dt 111.58ms | tok/sec: 293683.02 | ds 16.3s\n",
            "step   100 | loss 5.396574 | byte loss 1.3192 | lr 1.9997e-03 | norm 0.7019 | dt 116.84ms | tok/sec: 280453.32 | ds 17.4s\n",
            "step   110 | loss 5.244611 | byte loss 1.2821 | lr 1.9996e-03 | norm 1.7590 | dt 112.40ms | tok/sec: 291522.07 | ds 18.6s\n",
            "step   120 | loss 5.087147 | byte loss 1.2436 | lr 1.9994e-03 | norm 0.7013 | dt 114.83ms | tok/sec: 285349.08 | ds 19.8s\n",
            "step   130 | loss 4.922812 | byte loss 1.2034 | lr 1.9992e-03 | norm 0.8483 | dt 117.95ms | tok/sec: 277807.11 | ds 20.9s\n",
            "step   140 | loss 4.711212 | byte loss 1.1517 | lr 1.9990e-03 | norm 0.8015 | dt 118.17ms | tok/sec: 277293.69 | ds 22.1s\n",
            "step   150 | loss 4.563290 | byte loss 1.1155 | lr 1.9988e-03 | norm 0.5542 | dt 115.77ms | tok/sec: 283037.89 | ds 23.3s\n",
            "step   160 | loss 4.445427 | byte loss 1.0867 | lr 1.9985e-03 | norm 0.7989 | dt 114.86ms | tok/sec: 285291.03 | ds 24.4s\n",
            "step   170 | loss 4.352316 | byte loss 1.0640 | lr 1.9982e-03 | norm 0.7508 | dt 124.41ms | tok/sec: 263396.96 | ds 25.6s\n",
            "step   180 | loss 4.252608 | byte loss 1.0396 | lr 1.9979e-03 | norm 0.5871 | dt 120.20ms | tok/sec: 272601.68 | ds 26.8s\n",
            "step   190 | loss 4.188838 | byte loss 1.0240 | lr 1.9976e-03 | norm 0.6324 | dt 116.71ms | tok/sec: 280771.30 | ds 28.0s\n",
            "step   200 | loss 4.134482 | byte loss 1.0107 | lr 1.9973e-03 | norm 0.8434 | dt 118.50ms | tok/sec: 276529.34 | ds 29.1s\n",
            "step   210 | loss 4.093136 | byte loss 1.0006 | lr 1.9969e-03 | norm 1.1824 | dt 119.28ms | tok/sec: 274724.61 | ds 30.3s\n",
            "step   220 | loss 4.053105 | byte loss 0.9908 | lr 1.9965e-03 | norm 0.6835 | dt 119.36ms | tok/sec: 274526.51 | ds 31.5s\n",
            "step   230 | loss 4.013103 | byte loss 0.9810 | lr 1.9960e-03 | norm 0.4799 | dt 119.33ms | tok/sec: 274590.69 | ds 32.7s\n",
            "step   240 | loss 3.978322 | byte loss 0.9725 | lr 1.9956e-03 | norm 0.7281 | dt 117.24ms | tok/sec: 279499.71 | ds 33.8s\n",
            "sample 0: Lily went to the park and then,, the park. It was ready to her things that then down on the dog?\" Timmy said the park in his mom. \n",
            "\n",
            "The dog took the box. He took them. \n",
            "\n",
            "\"Thank you will have playing on the bird.\n",
            "\n",
            "As they were fun.\n",
            "sample 1: Lily went to the park and Tom saw a big and smiled. They were so curious they had the time to play in the little tree. He looked at the sky and started to bed and gave her and she smiled and Tom.\n",
            "\n",
            "\n",
            "The friends to be happy they did it was a big man was so time\n",
            "sample 2: Lily went to the park and said, no one can we you!\"\n",
            "Ben and the water with their mom's good friends. She was a tree. She had a big hug and his mom, but he wanted to find out.\n",
            "Then, they learned how to the ground and and played.\n",
            "One day,\n",
            "sample 3: Lily went to the park and he made a special. \n",
            "\n",
            "\"Hello goodbye to the story to see a smile?\" Max. Ben and hugged Tim and Ben are friends. Now her mom and Lily and said. She liked him.\n",
            "Her mom.\n",
            "\n",
            "\"We are not not a time and said but she\n",
            "reset, epoch change 3\n",
            "step 250 | val loss 3.9559 | byte loss 0.9670 | ds 49.1s\n",
            "step   250 | loss 3.952776 | byte loss 0.9663 | lr 1.9951e-03 | norm 0.7316 | dt 14833.05ms | tok/sec: 2209.12 | ds 49.7s\n",
            "step   260 | loss 3.911205 | byte loss 0.9561 | lr 1.9739e-03 | norm 0.8605 | dt 729.41ms | tok/sec: 44923.95 | ds 58.2s\n",
            "step   270 | loss 3.877794 | byte loss 0.9480 | lr 1.9699e-03 | norm 0.9421 | dt 674.87ms | tok/sec: 48554.83 | ds 66.2s\n",
            "step   280 | loss 3.826426 | byte loss 0.9354 | lr 1.9658e-03 | norm 1.0652 | dt 720.85ms | tok/sec: 45457.19 | ds 73.2s\n",
            "step   290 | loss 3.788919 | byte loss 0.9262 | lr 1.9612e-03 | norm 1.3098 | dt 708.41ms | tok/sec: 46256.01 | ds 81.4s\n",
            "step   300 | loss 3.761840 | byte loss 0.9196 | lr 1.9560e-03 | norm 1.5208 | dt 779.59ms | tok/sec: 42032.57 | ds 88.7s\n",
            "step   310 | loss 3.740108 | byte loss 0.9143 | lr 1.9504e-03 | norm 1.5962 | dt 696.86ms | tok/sec: 47022.21 | ds 97.2s\n",
            "step   320 | loss 3.720982 | byte loss 0.9096 | lr 1.9443e-03 | norm 1.7460 | dt 955.28ms | tok/sec: 34302.06 | ds 105.7s\n",
            "step   330 | loss 3.679173 | byte loss 0.8994 | lr 1.9367e-03 | norm 2.1147 | dt 700.79ms | tok/sec: 46758.52 | ds 112.9s\n",
            "step   340 | loss 3.630551 | byte loss 0.8875 | lr 1.9297e-03 | norm 1.7990 | dt 684.41ms | tok/sec: 47878.01 | ds 121.4s\n",
            "step   350 | loss 3.622104 | byte loss 0.8854 | lr 1.9220e-03 | norm 1.0208 | dt 745.35ms | tok/sec: 43963.20 | ds 128.5s\n",
            "step   360 | loss 3.595547 | byte loss 0.8790 | lr 1.9138e-03 | norm 1.2368 | dt 680.67ms | tok/sec: 48140.92 | ds 136.9s\n",
            "step   370 | loss 3.597599 | byte loss 0.8795 | lr 1.9049e-03 | norm 2.5911 | dt 1114.63ms | tok/sec: 29398.14 | ds 144.6s\n",
            "step   380 | loss 3.556881 | byte loss 0.8695 | lr 1.8932e-03 | norm 1.7748 | dt 707.18ms | tok/sec: 46335.93 | ds 152.5s\n",
            "step   390 | loss 3.513559 | byte loss 0.8589 | lr 1.8830e-03 | norm 1.2803 | dt 720.45ms | tok/sec: 45482.82 | ds 167.0s\n",
            "step   400 | loss 3.505776 | byte loss 0.8570 | lr 1.8695e-03 | norm 1.1533 | dt 1046.34ms | tok/sec: 31316.67 | ds 175.3s\n",
            "step   410 | loss 3.512609 | byte loss 0.8587 | lr 1.8553e-03 | norm 1.7797 | dt 713.39ms | tok/sec: 45932.55 | ds 182.7s\n",
            "step   420 | loss 3.463481 | byte loss 0.8467 | lr 1.8428e-03 | norm 1.7673 | dt 727.92ms | tok/sec: 45015.81 | ds 191.8s\n",
            "step   430 | loss 3.487325 | byte loss 0.8525 | lr 1.8286e-03 | norm 1.2951 | dt 736.06ms | tok/sec: 44518.10 | ds 198.8s\n",
            "step   440 | loss 3.470046 | byte loss 0.8483 | lr 1.8148e-03 | norm 1.4329 | dt 693.83ms | tok/sec: 47227.64 | ds 207.5s\n",
            "step   450 | loss 3.453562 | byte loss 0.8442 | lr 1.7994e-03 | norm 1.8199 | dt 717.41ms | tok/sec: 45675.47 | ds 214.6s\n",
            "step   460 | loss 3.423532 | byte loss 0.8369 | lr 1.7841e-03 | norm 1.7165 | dt 760.70ms | tok/sec: 43076.07 | ds 224.2s\n",
            "step   470 | loss 3.414174 | byte loss 0.8346 | lr 1.7659e-03 | norm 2.0089 | dt 708.46ms | tok/sec: 46252.48 | ds 231.3s\n",
            "step   480 | loss 3.407112 | byte loss 0.8329 | lr 1.7493e-03 | norm 2.0213 | dt 777.36ms | tok/sec: 42153.07 | ds 240.3s\n",
            "step   490 | loss 3.384211 | byte loss 0.8273 | lr 1.7294e-03 | norm 1.5113 | dt 1051.69ms | tok/sec: 31157.34 | ds 247.6s\n",
            "sample 0: Lily went to the park and Sam were scared. They thought, that Ben asked Lily, \"Look, a little boy, we are the little cat.\"\n",
            "\n",
            "\"Are a beautiful necklace?\" Sam said.\n",
            "\n",
            "\"Hello, \"We can we are. But you have a lot of candy. You are best\n",
            "sample 1: Lily went to the park and walked outside. She had a new snack.\n",
            "\n",
            "Tim was not wanted to see a gift for lunch. She asked her mom, but one of that he had a new new truck.\n",
            "\n",
            "John felt tired. She started to get to catch and happy. She put the ball home\n",
            "sample 2: Lily went to the park and Lily. His friend found them in her room she gave her and her a big hug.\n",
            "\n",
            "\"I want Lily, I will go to the store!\" Lily said, \"You are playing and your family in the swing.\" Tim said, \"Mommy, little bird. We did not\n",
            "sample 3: Lily went to the park and she took a new friend and put on a beautiful car. She went to play inside and ran away.\n",
            "\n",
            "His mom smiled and said, \"But you are very beautiful!\" But all, Lily said, a man and a little boy.\n",
            "\n",
            "But the girl came to buy the\n",
            "reset, epoch change 4\n",
            "step 500 | val loss 3.4101 | byte loss 0.8336 | ds 256.8s\n",
            "step   500 | loss 3.379218 | byte loss 0.8261 | lr 1.7070e-03 | norm 1.5477 | dt 1195.16ms | tok/sec: 27417.32 | ds 256.8s\n",
            "step   510 | loss 3.348197 | byte loss 0.8185 | lr 1.6803e-03 | norm 1.2198 | dt 116.32ms | tok/sec: 281693.77 | ds 257.9s\n",
            "step   520 | loss 3.335204 | byte loss 0.8153 | lr 1.6731e-03 | norm 1.7806 | dt 115.45ms | tok/sec: 283836.94 | ds 259.1s\n",
            "step   530 | loss 3.320847 | byte loss 0.8118 | lr 1.6656e-03 | norm 1.8358 | dt 118.72ms | tok/sec: 276012.87 | ds 260.3s\n",
            "step   540 | loss 3.327472 | byte loss 0.8134 | lr 1.6585e-03 | norm 1.5666 | dt 116.65ms | tok/sec: 280913.62 | ds 261.4s\n",
            "step   550 | loss 3.318530 | byte loss 0.8112 | lr 1.6512e-03 | norm 2.3831 | dt 117.43ms | tok/sec: 279054.23 | ds 262.6s\n",
            "step   560 | loss 3.298140 | byte loss 0.8063 | lr 1.6439e-03 | norm 1.6402 | dt 117.41ms | tok/sec: 279082.00 | ds 263.8s\n",
            "step   570 | loss 3.293584 | byte loss 0.8051 | lr 1.6371e-03 | norm 1.4050 | dt 114.38ms | tok/sec: 286478.57 | ds 265.0s\n",
            "step   580 | loss 3.277210 | byte loss 0.8011 | lr 1.6299e-03 | norm 1.7840 | dt 114.88ms | tok/sec: 285244.85 | ds 266.1s\n",
            "step   590 | loss 3.259674 | byte loss 0.7968 | lr 1.6228e-03 | norm 3.2422 | dt 115.49ms | tok/sec: 283737.91 | ds 267.3s\n",
            "step   600 | loss 3.285435 | byte loss 0.8031 | lr 1.6162e-03 | norm 1.9646 | dt 114.91ms | tok/sec: 285167.31 | ds 268.5s\n",
            "step   610 | loss 3.273722 | byte loss 0.8003 | lr 1.6093e-03 | norm 1.9002 | dt 116.57ms | tok/sec: 281107.82 | ds 269.7s\n",
            "step   620 | loss 3.249548 | byte loss 0.7944 | lr 1.6024e-03 | norm 2.4870 | dt 116.24ms | tok/sec: 281905.82 | ds 270.8s\n",
            "step   630 | loss 3.215664 | byte loss 0.7861 | lr 1.5960e-03 | norm 2.2271 | dt 113.14ms | tok/sec: 289625.64 | ds 272.0s\n",
            "step   640 | loss 3.232209 | byte loss 0.7901 | lr 1.5893e-03 | norm 2.2190 | dt 115.59ms | tok/sec: 283482.16 | ds 273.2s\n",
            "step   650 | loss 3.231675 | byte loss 0.7900 | lr 1.5827e-03 | norm 1.9751 | dt 115.94ms | tok/sec: 282633.95 | ds 274.4s\n",
            "step   660 | loss 3.230278 | byte loss 0.7897 | lr 1.5761e-03 | norm 1.3157 | dt 118.12ms | tok/sec: 277416.83 | ds 275.5s\n",
            "step   670 | loss 3.220061 | byte loss 0.7872 | lr 1.5696e-03 | norm 2.6210 | dt 117.85ms | tok/sec: 278039.21 | ds 276.7s\n",
            "step   680 | loss 3.223412 | byte loss 0.7880 | lr 1.5635e-03 | norm 2.2182 | dt 114.32ms | tok/sec: 286643.48 | ds 277.9s\n",
            "step   690 | loss 3.214479 | byte loss 0.7858 | lr 1.5571e-03 | norm 3.0680 | dt 115.96ms | tok/sec: 282589.20 | ds 279.0s\n",
            "step   700 | loss 3.203123 | byte loss 0.7830 | lr 1.5508e-03 | norm 2.9490 | dt 116.01ms | tok/sec: 282449.24 | ds 280.2s\n",
            "step   710 | loss 3.183009 | byte loss 0.7781 | lr 1.5446e-03 | norm 1.2879 | dt 114.15ms | tok/sec: 287070.96 | ds 281.4s\n",
            "step   720 | loss 3.179354 | byte loss 0.7772 | lr 1.5384e-03 | norm 1.7653 | dt 116.89ms | tok/sec: 280322.33 | ds 282.5s\n",
            "step   730 | loss 3.196015 | byte loss 0.7813 | lr 1.5323e-03 | norm 2.0478 | dt 114.98ms | tok/sec: 284994.65 | ds 283.7s\n",
            "step   740 | loss 3.162962 | byte loss 0.7732 | lr 1.5267e-03 | norm 1.6270 | dt 114.46ms | tok/sec: 286287.61 | ds 284.8s\n",
            "sample 0: Lily went to the park and saw a new friend. She said, \"Come on, Lily. A girl named Tim. Lily wanted to play hide a game with a day, she got the ball. She loved to play together for a day. She went playing at the park and saw a small dog. She didn\n",
            "sample 1: Lily went to the park and was the park. The game were sweet and pretty dog went outside. It looked around, and found his friend. He started to run and chase them until he saw a big rock, a bug. He had a new toy with the bird too hot sky.\n",
            "\n",
            "The little boy called\n",
            "sample 2: Lily went to the park and went to explore. She loved to explore the sun. She would take out the rain and find a big tree.\n",
            "\n",
            "One day, a little boy saw a big pile of leaves. The cat was very surprised and amazed by what was. The little. The cat said she was scared\n",
            "sample 3: Lily went to the park and found some sticks. She wanted it, and came to the park. They were just thought, and found a shiny red ball in the park. All of the sun were tired and wet and started to move. Timmy said, \"What is? I want to the park!\"\n",
            "\n",
            "Timmy\n",
            "reset, epoch change 5\n",
            "step 750 | val loss 3.2033 | byte loss 0.7831 | ds 286.9s\n",
            "step   750 | loss 3.150634 | byte loss 0.7702 | lr 1.5207e-03 | norm 2.1878 | dt 968.89ms | tok/sec: 33820.17 | ds 286.9s\n",
            "step   760 | loss 3.171577 | byte loss 0.7753 | lr 1.4986e-03 | norm 1.8384 | dt 113.71ms | tok/sec: 288180.31 | ds 288.0s\n",
            "step   770 | loss 3.153055 | byte loss 0.7708 | lr 1.4927e-03 | norm 2.4095 | dt 114.24ms | tok/sec: 286846.88 | ds 289.2s\n",
            "step   780 | loss 3.157084 | byte loss 0.7718 | lr 1.4869e-03 | norm 2.4864 | dt 113.68ms | tok/sec: 288254.05 | ds 290.3s\n",
            "step   790 | loss 3.153980 | byte loss 0.7710 | lr 1.4812e-03 | norm 1.3671 | dt 115.13ms | tok/sec: 284614.57 | ds 291.5s\n",
            "step   800 | loss 3.136412 | byte loss 0.7667 | lr 1.4755e-03 | norm 1.9075 | dt 115.58ms | tok/sec: 283509.06 | ds 292.6s\n",
            "step   810 | loss 3.140652 | byte loss 0.7678 | lr 1.4698e-03 | norm 2.3083 | dt 117.39ms | tok/sec: 279135.85 | ds 293.8s\n",
            "step   820 | loss 3.125380 | byte loss 0.7640 | lr 1.4643e-03 | norm 1.8860 | dt 116.58ms | tok/sec: 281071.03 | ds 295.0s\n",
            "step   830 | loss 3.118056 | byte loss 0.7622 | lr 1.4587e-03 | norm 1.6934 | dt 114.52ms | tok/sec: 286125.50 | ds 296.1s\n",
            "step   840 | loss 3.117759 | byte loss 0.7622 | lr 1.4533e-03 | norm 2.2448 | dt 111.98ms | tok/sec: 292611.32 | ds 297.3s\n",
            "step   850 | loss 3.108507 | byte loss 0.7599 | lr 1.4479e-03 | norm 2.4964 | dt 116.03ms | tok/sec: 282397.59 | ds 298.4s\n",
            "step   860 | loss 3.087873 | byte loss 0.7548 | lr 1.4426e-03 | norm 1.6751 | dt 114.34ms | tok/sec: 286577.73 | ds 299.5s\n",
            "step   870 | loss 3.087960 | byte loss 0.7549 | lr 1.4373e-03 | norm 2.4398 | dt 115.15ms | tok/sec: 284579.80 | ds 300.7s\n",
            "step   880 | loss 3.108614 | byte loss 0.7599 | lr 1.4317e-03 | norm 2.3969 | dt 117.17ms | tok/sec: 279668.63 | ds 301.8s\n",
            "step   890 | loss 3.081670 | byte loss 0.7533 | lr 1.4265e-03 | norm 2.1073 | dt 120.46ms | tok/sec: 272028.14 | ds 303.0s\n",
            "step   900 | loss 3.065325 | byte loss 0.7493 | lr 1.4214e-03 | norm 1.3182 | dt 108.80ms | tok/sec: 301174.01 | ds 304.1s\n",
            "step   910 | loss 3.084693 | byte loss 0.7541 | lr 1.4164e-03 | norm 1.2585 | dt 115.77ms | tok/sec: 283050.13 | ds 305.3s\n",
            "step   920 | loss 3.078361 | byte loss 0.7525 | lr 1.4114e-03 | norm 2.2628 | dt 113.40ms | tok/sec: 288960.70 | ds 306.4s\n",
            "step   930 | loss 3.090829 | byte loss 0.7556 | lr 1.4061e-03 | norm 1.9223 | dt 115.12ms | tok/sec: 284632.25 | ds 307.6s\n",
            "step   940 | loss 3.083535 | byte loss 0.7538 | lr 1.4012e-03 | norm 2.1317 | dt 115.91ms | tok/sec: 282696.73 | ds 308.7s\n",
            "step   950 | loss 3.088515 | byte loss 0.7550 | lr 1.3964e-03 | norm 2.0801 | dt 112.60ms | tok/sec: 291009.74 | ds 309.9s\n",
            "step   960 | loss 3.060704 | byte loss 0.7482 | lr 1.3912e-03 | norm 2.2210 | dt 116.03ms | tok/sec: 282405.13 | ds 311.0s\n",
            "step   970 | loss 3.048163 | byte loss 0.7451 | lr 1.3865e-03 | norm 1.6743 | dt 115.19ms | tok/sec: 284473.19 | ds 312.2s\n",
            "step   980 | loss 3.052449 | byte loss 0.7462 | lr 1.3818e-03 | norm 3.1462 | dt 112.46ms | tok/sec: 291380.53 | ds 313.3s\n",
            "step   990 | loss 3.061005 | byte loss 0.7483 | lr 1.3767e-03 | norm 1.7322 | dt 111.62ms | tok/sec: 293558.19 | ds 314.5s\n",
            "sample 0: Lily went to the park and saw a beautiful butterfly and found lots of fruit outside. She had no ice ice cream with and found the jar. It was a very messy, and her friends. Her mom was too heavy and asked and asked his mommy, \"But this is not a good idea. It's a small\n",
            "sample 1: Lily went to the park and started to spin. But the ball jumped and down her finger was scared. But the boy told him if they could not to play. He knew it on the ground. He looked for a haircut. He had a idea. He was going to make it down the slide.\n",
            "\n",
            "Mom\n",
            "sample 2: Lily went to the park and Lily. She wanted to be it at the playground. She looked like that she couldn't believe her eyes.\n",
            "\n",
            "\"Look,, Lily, I made a lot. I have a snack! I won't touch it!\" Max said.\n",
            "\n",
            "She pulled her finger and smiled.\n",
            "sample 3: Lily went to the park and asked, \"Mom, I will see a slide. I can find it!\" said, \"Yes, I have something to play outside, kids we have to play in the park?\" The game laughed and said hello.\n",
            "\n",
            "\"Let's go to the park?\"\n",
            "\n",
            "\n",
            "Lily\n",
            "reset, epoch change 6\n",
            "step 1000 | val loss 3.0984 | byte loss 0.7574 | ds 330.9s\n",
            "step  1000 | loss 3.037333 | byte loss 0.7425 | lr 1.3722e-03 | norm 2.3240 | dt 16008.96ms | tok/sec: 2046.85 | ds 331.5s\n",
            "step  1010 | loss 3.036094 | byte loss 0.7422 | lr 1.0289e-03 | norm 1.7406 | dt 674.18ms | tok/sec: 48604.38 | ds 338.6s\n",
            "step  1020 | loss 3.032412 | byte loss 0.7413 | lr 1.0045e-03 | norm 1.7223 | dt 848.96ms | tok/sec: 38598.03 | ds 347.3s\n",
            "step  1030 | loss 3.025876 | byte loss 0.7397 | lr 9.7474e-04 | norm 1.8441 | dt 836.91ms | tok/sec: 39153.45 | ds 356.4s\n",
            "step  1040 | loss 3.043042 | byte loss 0.7439 | lr 9.4458e-04 | norm 1.0417 | dt 871.95ms | tok/sec: 37580.05 | ds 365.0s\n",
            "step  1050 | loss 3.023266 | byte loss 0.7391 | lr 9.1491e-04 | norm 1.1006 | dt 712.30ms | tok/sec: 46003.32 | ds 373.1s\n",
            "step  1060 | loss 3.016822 | byte loss 0.7375 | lr 8.8853e-04 | norm 1.6160 | dt 685.58ms | tok/sec: 47795.69 | ds 380.1s\n",
            "step  1070 | loss 3.000086 | byte loss 0.7334 | lr 8.6472e-04 | norm 1.2799 | dt 855.21ms | tok/sec: 38315.74 | ds 389.4s\n",
            "step  1080 | loss 3.030044 | byte loss 0.7407 | lr 8.3435e-04 | norm 1.1162 | dt 853.06ms | tok/sec: 38412.45 | ds 398.3s\n",
            "step  1090 | loss 3.012221 | byte loss 0.7364 | lr 8.0469e-04 | norm 2.8804 | dt 862.50ms | tok/sec: 37991.72 | ds 407.0s\n",
            "step  1100 | loss 3.001841 | byte loss 0.7338 | lr 7.7584e-04 | norm 2.0110 | dt 869.33ms | tok/sec: 37693.36 | ds 415.5s\n",
            "step  1110 | loss 3.011526 | byte loss 0.7362 | lr 7.4786e-04 | norm 2.8355 | dt 676.04ms | tok/sec: 48470.22 | ds 423.8s\n",
            "step  1120 | loss 3.011492 | byte loss 0.7362 | lr 7.2181e-04 | norm 1.2850 | dt 698.74ms | tok/sec: 46895.62 | ds 430.9s\n",
            "step  1130 | loss 3.016854 | byte loss 0.7375 | lr 6.9973e-04 | norm 2.9906 | dt 857.57ms | tok/sec: 38210.50 | ds 439.8s\n",
            "step  1140 | loss 2.991907 | byte loss 0.7314 | lr 6.7184e-04 | norm 1.6949 | dt 883.10ms | tok/sec: 37105.49 | ds 448.3s\n",
            "step  1150 | loss 2.994898 | byte loss 0.7321 | lr 6.4505e-04 | norm 1.7950 | dt 861.27ms | tok/sec: 38046.07 | ds 456.9s\n",
            "step  1160 | loss 3.004015 | byte loss 0.7343 | lr 6.1840e-04 | norm 1.3725 | dt 859.42ms | tok/sec: 38127.98 | ds 465.5s\n",
            "step  1170 | loss 3.010167 | byte loss 0.7359 | lr 5.9294e-04 | norm 1.3433 | dt 820.07ms | tok/sec: 39957.52 | ds 474.0s\n",
            "step  1180 | loss 2.980718 | byte loss 0.7287 | lr 5.6873e-04 | norm 0.8803 | dt 833.91ms | tok/sec: 39294.57 | ds 482.7s\n",
            "step  1190 | loss 2.992827 | byte loss 0.7316 | lr 5.4380e-04 | norm 1.1520 | dt 886.20ms | tok/sec: 36975.69 | ds 491.2s\n",
            "step  1200 | loss 2.978545 | byte loss 0.7281 | lr 5.2021e-04 | norm 1.1833 | dt 700.80ms | tok/sec: 46757.93 | ds 498.9s\n",
            "step  1210 | loss 2.988817 | byte loss 0.7306 | lr 4.9991e-04 | norm 1.2257 | dt 867.63ms | tok/sec: 37767.33 | ds 506.0s\n",
            "step  1220 | loss 3.003337 | byte loss 0.7342 | lr 4.7997e-04 | norm 1.0148 | dt 876.79ms | tok/sec: 37372.78 | ds 515.1s\n",
            "step  1230 | loss 2.984528 | byte loss 0.7296 | lr 4.5662e-04 | norm 1.4163 | dt 886.50ms | tok/sec: 36963.19 | ds 523.6s\n",
            "step  1240 | loss 2.977379 | byte loss 0.7278 | lr 4.3568e-04 | norm 1.1430 | dt 900.53ms | tok/sec: 36387.52 | ds 532.1s\n",
            "sample 0: Lily went to the park and saw a pretty butterfly in the butterfly. She went to the park to found all the beautiful pink ball and shiny. \n",
            "\n",
            "Lily and Lily was very surprised to see Lily. She loved the butterfly too.\n",
            "\n",
            "\"Look, what this is pretty!\" Lily said, \"It's cool\n",
            "sample 1: Lily went to the park and Timmy made a big hug. Lily fell down the dark rain and fell on a branch to her bed.\n",
            "\n",
            "Lily tried to catch it on it, but it was too hard, but just just in it was the cold. But, they still started to cry. Lily didn't give\n",
            "sample 2: Lily went to the park and went to explore. She ran to the park outside and saw her mommy and daddy. They saw a big dog and and Max. They saw a big, scary dog. They wanted a big hole too.\n",
            "\n",
            "\"Roar, Sam, I found the little boy and the man. It\n",
            "sample 3: Lily went to the park and asked him to make a big dog to go close. But then, it's my owner named Max. Max said Timmy, \"Let's pretend if he was too fast and be lazy and his name was. Lily's mommy told him that he was very good for his mommy. His dad\n",
            "reset, epoch change 7\n",
            "step 1250 | val loss 3.0146 | byte loss 0.7369 | ds 541.1s\n",
            "step  1250 | loss 2.967618 | byte loss 0.7255 | lr 4.1528e-04 | norm 0.9012 | dt 1322.73ms | tok/sec: 24773.00 | ds 541.1s\n",
            "step  1260 | loss 2.971889 | byte loss 0.7265 | lr 3.9276e-04 | norm 1.1114 | dt 117.92ms | tok/sec: 277882.93 | ds 542.3s\n",
            "step  1270 | loss 2.966610 | byte loss 0.7252 | lr 3.9037e-04 | norm 0.8019 | dt 117.37ms | tok/sec: 279175.54 | ds 543.4s\n",
            "step  1280 | loss 2.985927 | byte loss 0.7299 | lr 3.8889e-04 | norm 1.0590 | dt 114.23ms | tok/sec: 286848.08 | ds 544.6s\n",
            "step  1290 | loss 2.968642 | byte loss 0.7257 | lr 3.8658e-04 | norm 1.6500 | dt 116.32ms | tok/sec: 281701.28 | ds 545.8s\n",
            "step  1300 | loss 2.969680 | byte loss 0.7260 | lr 3.8516e-04 | norm 1.4029 | dt 116.14ms | tok/sec: 282143.67 | ds 546.9s\n",
            "step  1310 | loss 2.974082 | byte loss 0.7270 | lr 3.8292e-04 | norm 0.9161 | dt 117.78ms | tok/sec: 278212.00 | ds 548.1s\n",
            "step  1320 | loss 2.961662 | byte loss 0.7240 | lr 3.8072e-04 | norm 1.1380 | dt 124.29ms | tok/sec: 263642.52 | ds 549.3s\n",
            "step  1330 | loss 2.955463 | byte loss 0.7225 | lr 3.7856e-04 | norm 1.0775 | dt 115.31ms | tok/sec: 284179.09 | ds 550.5s\n",
            "step  1340 | loss 2.965468 | byte loss 0.7249 | lr 3.7726e-04 | norm 1.2373 | dt 116.48ms | tok/sec: 281313.23 | ds 551.6s\n",
            "step  1350 | loss 2.963262 | byte loss 0.7244 | lr 3.7516e-04 | norm 1.5329 | dt 117.26ms | tok/sec: 279442.89 | ds 552.8s\n",
            "step  1360 | loss 2.957313 | byte loss 0.7229 | lr 3.7310e-04 | norm 1.0937 | dt 116.01ms | tok/sec: 282466.08 | ds 554.0s\n",
            "step  1370 | loss 2.956391 | byte loss 0.7227 | lr 3.7108e-04 | norm 1.4908 | dt 112.87ms | tok/sec: 290319.42 | ds 555.2s\n",
            "step  1380 | loss 2.949962 | byte loss 0.7211 | lr 3.6989e-04 | norm 1.2512 | dt 116.77ms | tok/sec: 280625.11 | ds 556.3s\n",
            "step  1390 | loss 2.946385 | byte loss 0.7203 | lr 3.6792e-04 | norm 1.0500 | dt 116.13ms | tok/sec: 282159.89 | ds 557.5s\n",
            "step  1400 | loss 2.958692 | byte loss 0.7233 | lr 3.6600e-04 | norm 1.1599 | dt 118.13ms | tok/sec: 277379.87 | ds 558.7s\n",
            "step  1410 | loss 2.942901 | byte loss 0.7194 | lr 3.6410e-04 | norm 0.9616 | dt 117.96ms | tok/sec: 277778.47 | ds 559.9s\n",
            "step  1420 | loss 2.957328 | byte loss 0.7229 | lr 3.6223e-04 | norm 1.2170 | dt 119.23ms | tok/sec: 274827.89 | ds 561.0s\n",
            "step  1430 | loss 2.950199 | byte loss 0.7212 | lr 3.6040e-04 | norm 1.0122 | dt 117.98ms | tok/sec: 277743.10 | ds 562.2s\n",
            "step  1440 | loss 2.954456 | byte loss 0.7222 | lr 3.5860e-04 | norm 1.0996 | dt 117.27ms | tok/sec: 279420.73 | ds 563.4s\n",
            "step  1450 | loss 2.955472 | byte loss 0.7225 | lr 3.5682e-04 | norm 1.5449 | dt 116.60ms | tok/sec: 281019.30 | ds 564.5s\n",
            "step  1460 | loss 2.949398 | byte loss 0.7210 | lr 3.5508e-04 | norm 1.3378 | dt 115.67ms | tok/sec: 283297.51 | ds 565.7s\n",
            "step  1470 | loss 2.952047 | byte loss 0.7216 | lr 3.5336e-04 | norm 1.2290 | dt 117.17ms | tok/sec: 279650.99 | ds 566.9s\n",
            "step  1480 | loss 2.942366 | byte loss 0.7193 | lr 3.5168e-04 | norm 1.1745 | dt 118.56ms | tok/sec: 276388.65 | ds 568.0s\n",
            "step  1490 | loss 2.942381 | byte loss 0.7193 | lr 3.5002e-04 | norm 1.4991 | dt 116.56ms | tok/sec: 281127.37 | ds 569.2s\n",
            "sample 0: Lily went to the park and saw a boy. He picked his mommy and started to shake the rain. \n",
            "\n",
            "But then she was running and started to cry. Lily felt scared for being so scary to cry. Her mom gave her her new mom a smile happily to her mommy.\n",
            "\n",
            "Later that day, Lily\n",
            "sample 1: Lily went to the park and put the orange and the pink and found a shiny gem. They saw many many flowers in the sky. It was red and shiny. It started to grass and it was too fast.\n",
            "\n",
            "\"Ha ha, no, this is too high into the sky. It is not nice.\n",
            "sample 2: Lily went to the park and said, \"Hello, Mr. The little squirrel was so angry, Lily said, \"I'm sorry, but you did not know that. I don't want to take it back to the owner. I understand you tell you, Lily. They tell Ben, okay, Lily. They\n",
            "sample 3: Lily went to the park and saw the park. She saw the other children of the park. She asked, \"Do you like her name?\" Sara asked her mother.\n",
            "\n",
            "\"I don't want to run away from me. I do a snake!\"\n",
            "\n",
            "\"I'm sorry, Ben. I love it\n",
            "reset, epoch change 8\n",
            "step 1500 | val loss 2.9889 | byte loss 0.7306 | ds 571.4s\n",
            "step  1500 | loss 2.940228 | byte loss 0.7188 | lr 3.4838e-04 | norm 1.4349 | dt 1113.56ms | tok/sec: 29426.38 | ds 571.4s\n",
            "step  1510 | loss 2.931964 | byte loss 0.7167 | lr 3.3976e-04 | norm 1.0400 | dt 116.05ms | tok/sec: 282357.56 | ds 572.5s\n",
            "step  1520 | loss 2.963274 | byte loss 0.7244 | lr 3.3825e-04 | norm 1.0715 | dt 115.99ms | tok/sec: 282503.81 | ds 573.7s\n",
            "step  1530 | loss 2.949850 | byte loss 0.7211 | lr 3.3676e-04 | norm 1.3275 | dt 114.98ms | tok/sec: 284994.65 | ds 574.8s\n",
            "step  1540 | loss 2.942085 | byte loss 0.7192 | lr 3.3529e-04 | norm 1.4190 | dt 112.85ms | tok/sec: 290374.01 | ds 576.0s\n",
            "step  1550 | loss 2.946969 | byte loss 0.7204 | lr 3.3384e-04 | norm 0.9077 | dt 115.95ms | tok/sec: 282610.70 | ds 577.2s\n",
            "step  1560 | loss 2.950967 | byte loss 0.7214 | lr 3.3176e-04 | norm 1.1481 | dt 115.07ms | tok/sec: 284765.54 | ds 578.3s\n",
            "step  1570 | loss 2.931394 | byte loss 0.7166 | lr 3.3036e-04 | norm 1.2043 | dt 115.32ms | tok/sec: 284145.60 | ds 579.5s\n",
            "step  1580 | loss 2.926963 | byte loss 0.7155 | lr 3.2899e-04 | norm 1.3517 | dt 110.64ms | tok/sec: 296175.28 | ds 580.6s\n",
            "step  1590 | loss 2.950690 | byte loss 0.7213 | lr 3.2699e-04 | norm 1.2563 | dt 123.26ms | tok/sec: 265851.20 | ds 581.8s\n",
            "step  1600 | loss 2.944002 | byte loss 0.7197 | lr 3.2567e-04 | norm 1.5407 | dt 112.97ms | tok/sec: 290067.59 | ds 582.9s\n",
            "step  1610 | loss 2.904629 | byte loss 0.7101 | lr 3.2437e-04 | norm 1.1433 | dt 114.65ms | tok/sec: 285798.85 | ds 584.1s\n",
            "step  1620 | loss 2.924327 | byte loss 0.7149 | lr 3.2246e-04 | norm 0.9646 | dt 116.41ms | tok/sec: 281493.57 | ds 585.3s\n",
            "step  1630 | loss 2.933991 | byte loss 0.7172 | lr 3.2120e-04 | norm 1.2447 | dt 115.28ms | tok/sec: 284243.15 | ds 586.4s\n",
            "step  1640 | loss 2.935922 | byte loss 0.7177 | lr 3.1934e-04 | norm 1.1405 | dt 114.05ms | tok/sec: 287301.99 | ds 587.5s\n",
            "step  1650 | loss 2.919756 | byte loss 0.7138 | lr 3.1813e-04 | norm 0.9876 | dt 118.25ms | tok/sec: 277107.51 | ds 588.7s\n",
            "step  1660 | loss 2.928796 | byte loss 0.7160 | lr 3.1633e-04 | norm 1.3316 | dt 115.04ms | tok/sec: 284849.93 | ds 589.8s\n",
            "step  1670 | loss 2.925165 | byte loss 0.7151 | lr 3.1516e-04 | norm 1.2978 | dt 116.71ms | tok/sec: 280771.87 | ds 591.0s\n",
            "step  1680 | loss 2.923826 | byte loss 0.7147 | lr 3.1341e-04 | norm 1.4057 | dt 110.55ms | tok/sec: 296414.18 | ds 592.1s\n",
            "step  1690 | loss 2.924619 | byte loss 0.7149 | lr 3.1227e-04 | norm 1.0286 | dt 118.68ms | tok/sec: 276096.60 | ds 593.3s\n",
            "step  1700 | loss 2.933161 | byte loss 0.7170 | lr 3.1058e-04 | norm 1.4207 | dt 115.09ms | tok/sec: 284717.75 | ds 594.4s\n",
            "step  1710 | loss 2.942607 | byte loss 0.7193 | lr 3.0948e-04 | norm 1.4359 | dt 114.48ms | tok/sec: 286242.30 | ds 595.6s\n",
            "step  1720 | loss 2.934271 | byte loss 0.7173 | lr 3.0783e-04 | norm 1.4266 | dt 125.65ms | tok/sec: 260789.53 | ds 596.8s\n",
            "step  1730 | loss 2.939597 | byte loss 0.7186 | lr 3.0621e-04 | norm 1.2233 | dt 119.59ms | tok/sec: 274008.75 | ds 597.9s\n",
            "step  1740 | loss 2.916947 | byte loss 0.7131 | lr 3.0461e-04 | norm 2.0785 | dt 110.51ms | tok/sec: 296524.17 | ds 599.0s\n",
            "sample 0: Lily went to the park and saw a ball. They thought that said Ben's mom, \"You'll take a stick!\" \n",
            "\n",
            "Ben and Ben liked to go for the ball. She picked it up and grabbed them. The balloon flew out and pushed, Lily to the slide. She had no blocks and the swing\n",
            "sample 1: Lily went to the park and picked it up. Lily was very friendly and happy-ed her friend. Lily and Lily went home she found a nice picture of a new garden. \n",
            "\n",
            "Lily was so happy. She got up the sky and looked around for the world for bed. She saw a big smile and gentle\n",
            "sample 2: Lily went to the park and went to look on the sandbox. Her mom laughed and said that the park was much fun. She was so excited that she could have her favorite toy on a big box. She said, \"Mommy, sweetie. I bet it just like it's time with it!\" \n",
            "\n",
            "Lily smiled\n",
            "sample 3: Lily went to the park and saw the park. She saw the dog, which was very selfish. She was kind and generous. She said to Sue, â€œYes, my dog! I am hurt you better!\"\n",
            "\n",
            "The dog had no problem, sad too. She said, \"You can't touch your\n",
            "reset, epoch change 9\n",
            "step 1750 | val loss 2.9705 | byte loss 0.7262 | ds 618.3s\n",
            "step  1750 | loss 2.928505 | byte loss 0.7159 | lr 3.0304e-04 | norm 1.0273 | dt 19018.78ms | tok/sec: 1722.93 | ds 619.1s\n",
            "step  1760 | loss 2.922483 | byte loss 0.7144 | lr 2.3531e-04 | norm 1.1938 | dt 906.81ms | tok/sec: 36135.39 | ds 628.2s\n",
            "step  1770 | loss 2.947248 | byte loss 0.7205 | lr 2.2877e-04 | norm 1.4793 | dt 950.42ms | tok/sec: 34477.54 | ds 637.4s\n",
            "step  1780 | loss 2.900726 | byte loss 0.7091 | lr 2.2286e-04 | norm 1.2249 | dt 893.53ms | tok/sec: 36672.57 | ds 646.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "KeyboardInterrupt\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate(m, enc, \"Lily went to the park and saw a friendly dog.\", 255, 4)"
      ],
      "metadata": {
        "id": "bDOa_PWgwPSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeeSKtNWUedE"
      },
      "source": [
        "If your text file is larger than 10MB, it is recommended to upload that file to Google Drive first, then copy that file from Google Drive to the Colaboratory VM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z6okFD8VKtS"
      },
      "source": [
        "copy_file_from_gdrive(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}